{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 8])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 8])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 64])\n",
      "Transferred 869/869 items from pretrained weights\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT241.png: 416x640 (no detections), 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT282.png: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.6ms preprocess, 37.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT340.png: 256x640 (no detections), 87.0ms\n",
      "Speed: 2.1ms preprocess, 87.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT341.png: 256x640 (no detections), 40.2ms\n",
      "Speed: 1.9ms preprocess, 40.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT001.png: 640x608 (no detections), 87.8ms\n",
      "Speed: 3.9ms preprocess, 87.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT002.png: 640x608 (no detections), 37.9ms\n",
      "Speed: 3.4ms preprocess, 37.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT003.png: 640x608 (no detections), 38.9ms\n",
      "Speed: 3.4ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT004.png: 640x608 (no detections), 39.4ms\n",
      "Speed: 3.4ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT005.png: 640x608 (no detections), 39.6ms\n",
      "Speed: 3.5ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 152])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 76])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 38])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 19])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 152])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT006.png: 640x608 (no detections), 40.3ms\n",
      "Speed: 3.4ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 152, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 76, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 19, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 76, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 19, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 152, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT007.png: 608x640 (no detections), 87.9ms\n",
      "Speed: 3.5ms preprocess, 87.9ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 152, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 76, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 19, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 76, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 38, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 19, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 152, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT008.png: 608x640 (no detections), 40.1ms\n",
      "Speed: 3.4ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 144, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 72, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 36, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 18, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 36, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 72, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 36, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 144, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT009.png: 576x640 (no detections), 85.4ms\n",
      "Speed: 3.6ms preprocess, 85.4ms inference, 0.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT010.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 3.0ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT011.png: 416x640 (no detections), 40.5ms\n",
      "Speed: 2.8ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT012.png: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.7ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT013.png: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.7ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT014.png: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.7ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT015.png: 384x640 (no detections), 40.9ms\n",
      "Speed: 2.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT016.png: 384x640 (no detections), 44.5ms\n",
      "Speed: 3.0ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT017.png: 384x640 (no detections), 36.4ms\n",
      "Speed: 2.7ms preprocess, 36.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT018.png: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.7ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT019.png: 384x640 (no detections), 38.7ms\n",
      "Speed: 2.6ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT020.png: 352x640 (no detections), 83.5ms\n",
      "Speed: 2.5ms preprocess, 83.5ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT021.png: 352x640 (no detections), 39.6ms\n",
      "Speed: 2.5ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT022.png: 352x640 (no detections), 39.1ms\n",
      "Speed: 2.5ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT023.png: 352x640 1 0, 39.3ms\n",
      "Speed: 2.5ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT024.png: 352x640 (no detections), 44.0ms\n",
      "Speed: 2.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT025.png: 352x640 (no detections), 41.2ms\n",
      "Speed: 2.6ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT026.png: 352x640 (no detections), 41.6ms\n",
      "Speed: 2.5ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT027.png: 320x640 (no detections), 86.5ms\n",
      "Speed: 2.3ms preprocess, 86.5ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT028.png: 320x640 (no detections), 39.1ms\n",
      "Speed: 2.4ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT029.png: 320x640 (no detections), 37.8ms\n",
      "Speed: 2.3ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT030.png: 320x640 (no detections), 38.2ms\n",
      "Speed: 2.3ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT031.png: 320x640 1 0, 37.8ms\n",
      "Speed: 2.5ms preprocess, 37.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT032.png: 320x640 1 0, 42.4ms\n",
      "Speed: 2.3ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT033.png: 320x640 (no detections), 47.1ms\n",
      "Speed: 2.4ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT034.png: 320x640 (no detections), 38.9ms\n",
      "Speed: 2.3ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT035.png: 320x640 (no detections), 38.3ms\n",
      "Speed: 2.3ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT036.png: 288x640 (no detections), 85.6ms\n",
      "Speed: 2.4ms preprocess, 85.6ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT037.png: 288x640 (no detections), 38.9ms\n",
      "Speed: 2.2ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT038.png: 288x640 1 0, 39.7ms\n",
      "Speed: 2.2ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT039.png: 288x640 1 0, 41.5ms\n",
      "Speed: 2.2ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT040.png: 288x640 (no detections), 43.0ms\n",
      "Speed: 2.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT041.png: 288x640 (no detections), 40.9ms\n",
      "Speed: 2.3ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT042.png: 288x640 (no detections), 39.2ms\n",
      "Speed: 2.2ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT043.png: 288x640 (no detections), 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT044.png: 288x640 (no detections), 39.6ms\n",
      "Speed: 2.1ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT045.png: 288x640 (no detections), 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT046.png: 288x640 (no detections), 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT047.png: 288x640 (no detections), 41.8ms\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT048.png: 288x640 (no detections), 37.8ms\n",
      "Speed: 2.6ms preprocess, 37.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT049.png: 288x640 (no detections), 38.5ms\n",
      "Speed: 2.1ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT050.png: 288x640 1 0, 39.4ms\n",
      "Speed: 2.1ms preprocess, 39.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT051.png: 288x640 1 0, 40.1ms\n",
      "Speed: 2.2ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT052.png: 320x640 1 0, 40.7ms\n",
      "Speed: 2.3ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT053.png: 352x640 (no detections), 39.1ms\n",
      "Speed: 2.5ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT054.png: 352x640 (no detections), 44.1ms\n",
      "Speed: 2.7ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT055.png: 352x640 (no detections), 39.6ms\n",
      "Speed: 2.5ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT056.png: 320x640 1 0, 40.3ms\n",
      "Speed: 2.3ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT057.png: 320x640 (no detections), 41.0ms\n",
      "Speed: 2.3ms preprocess, 41.0ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT058.png: 320x640 1 0, 39.0ms\n",
      "Speed: 2.3ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT059.png: 320x640 (no detections), 42.7ms\n",
      "Speed: 2.4ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT060.png: 288x640 (no detections), 40.3ms\n",
      "Speed: 2.2ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT061.png: 288x640 (no detections), 39.3ms\n",
      "Speed: 2.1ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT062.png: 288x640 (no detections), 39.8ms\n",
      "Speed: 2.0ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT063.png: 288x640 (no detections), 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT064.png: 288x640 (no detections), 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT065.png: 288x640 (no detections), 38.2ms\n",
      "Speed: 2.0ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT066.png: 288x640 (no detections), 38.6ms\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT067.png: 288x640 (no detections), 39.3ms\n",
      "Speed: 2.0ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT068.png: 288x640 (no detections), 40.1ms\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT069.png: 288x640 (no detections), 38.1ms\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT070.png: 288x640 (no detections), 38.7ms\n",
      "Speed: 2.0ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT071.png: 288x640 (no detections), 40.4ms\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT072.png: 288x640 (no detections), 39.9ms\n",
      "Speed: 2.1ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT073.png: 288x640 (no detections), 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT074.png: 288x640 (no detections), 38.2ms\n",
      "Speed: 2.1ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT075.png: 320x640 (no detections), 41.6ms\n",
      "Speed: 2.2ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT076.png: 320x640 (no detections), 39.2ms\n",
      "Speed: 2.2ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT077.png: 320x640 (no detections), 38.6ms\n",
      "Speed: 2.2ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT078.png: 320x640 (no detections), 38.2ms\n",
      "Speed: 2.3ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT079.png: 320x640 1 0, 39.5ms\n",
      "Speed: 2.3ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT080.png: 352x640 (no detections), 40.5ms\n",
      "Speed: 2.4ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT081.png: 352x640 (no detections), 39.0ms\n",
      "Speed: 2.4ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT082.png: 352x640 (no detections), 44.6ms\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT083.png: 352x640 (no detections), 38.6ms\n",
      "Speed: 2.5ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT084.png: 352x640 (no detections), 41.1ms\n",
      "Speed: 2.4ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT085.png: 352x640 1 0, 39.6ms\n",
      "Speed: 2.5ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT086.png: 352x640 (no detections), 40.8ms\n",
      "Speed: 2.5ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT087.png: 352x640 (no detections), 39.2ms\n",
      "Speed: 2.5ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT088.png: 352x640 (no detections), 38.7ms\n",
      "Speed: 2.4ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT089.png: 352x640 (no detections), 41.0ms\n",
      "Speed: 2.4ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT090.png: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.6ms preprocess, 41.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT091.png: 384x640 (no detections), 40.3ms\n",
      "Speed: 2.6ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT092.png: 384x640 (no detections), 39.4ms\n",
      "Speed: 2.6ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT093.png: 384x640 1 0, 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT094.png: 384x640 (no detections), 42.2ms\n",
      "Speed: 2.6ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT095.png: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT096.png: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.6ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT097.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.6ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT098.png: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.6ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT099.png: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT100.png: 384x640 1 0, 43.9ms\n",
      "Speed: 2.7ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT101.png: 384x640 1 0, 38.7ms\n",
      "Speed: 2.6ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT102.png: 384x640 (no detections), 41.5ms\n",
      "Speed: 2.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT103.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.7ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT104.png: 384x640 (no detections), 36.9ms\n",
      "Speed: 2.6ms preprocess, 36.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT105.png: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.6ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT106.png: 384x640 1 0, 39.6ms\n",
      "Speed: 2.6ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT107.png: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT108.png: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.6ms preprocess, 36.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT109.png: 384x640 1 0, 37.5ms\n",
      "Speed: 2.6ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT110.png: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.7ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT111.png: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.6ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT112.png: 384x640 (no detections), 38.9ms\n",
      "Speed: 2.6ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT113.png: 416x640 (no detections), 39.2ms\n",
      "Speed: 3.2ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT114.png: 416x640 (no detections), 40.2ms\n",
      "Speed: 2.7ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT115.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 2.7ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT116.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 2.7ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT117.png: 416x640 (no detections), 39.0ms\n",
      "Speed: 2.7ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT118.png: 416x640 1 0, 39.7ms\n",
      "Speed: 2.9ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT119.png: 416x640 1 0, 40.2ms\n",
      "Speed: 2.7ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT120.png: 416x640 1 0, 40.1ms\n",
      "Speed: 2.7ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT121.png: 416x640 (no detections), 41.3ms\n",
      "Speed: 2.7ms preprocess, 41.3ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT122.png: 416x640 1 0, 39.1ms\n",
      "Speed: 2.7ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT123.png: 416x640 (no detections), 40.9ms\n",
      "Speed: 2.8ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT124.png: 416x640 (no detections), 40.8ms\n",
      "Speed: 2.8ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT125.png: 448x640 1 0, 85.1ms\n",
      "Speed: 3.2ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT126.png: 448x640 (no detections), 41.5ms\n",
      "Speed: 2.9ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT127.png: 448x640 1 0, 38.3ms\n",
      "Speed: 2.9ms preprocess, 38.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT128.png: 448x640 1 0, 39.9ms\n",
      "Speed: 2.8ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT129.png: 448x640 1 0, 43.2ms\n",
      "Speed: 2.9ms preprocess, 43.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT130.png: 448x640 1 0, 41.5ms\n",
      "Speed: 2.8ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT131.png: 448x640 1 0, 41.6ms\n",
      "Speed: 2.8ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT132.png: 448x640 (no detections), 38.7ms\n",
      "Speed: 2.8ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT133.png: 448x640 (no detections), 39.6ms\n",
      "Speed: 2.8ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT134.png: 448x640 (no detections), 39.8ms\n",
      "Speed: 2.9ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT135.png: 448x640 (no detections), 40.2ms\n",
      "Speed: 2.9ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT136.png: 448x640 (no detections), 40.3ms\n",
      "Speed: 3.0ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT137.png: 448x640 (no detections), 39.1ms\n",
      "Speed: 3.0ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT138.png: 448x640 1 0, 44.7ms\n",
      "Speed: 3.0ms preprocess, 44.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT139.png: 448x640 (no detections), 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT140.png: 448x640 (no detections), 40.5ms\n",
      "Speed: 2.9ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT141.png: 448x640 (no detections), 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT142.png: 448x640 (no detections), 38.5ms\n",
      "Speed: 2.9ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT143.png: 448x640 (no detections), 39.2ms\n",
      "Speed: 2.9ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT144.png: 448x640 1 0, 39.4ms\n",
      "Speed: 2.9ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT145.png: 448x640 1 0, 43.2ms\n",
      "Speed: 2.9ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT146.png: 448x640 1 0, 41.5ms\n",
      "Speed: 2.9ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT147.png: 448x640 1 0, 39.0ms\n",
      "Speed: 2.9ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT148.png: 448x640 1 0, 40.2ms\n",
      "Speed: 2.9ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT149.png: 480x640 1 0, 86.2ms\n",
      "Speed: 3.6ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT150.png: 480x640 (no detections), 41.5ms\n",
      "Speed: 3.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT151.png: 480x640 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT152.png: 480x640 (no detections), 38.7ms\n",
      "Speed: 3.0ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT153.png: 480x640 (no detections), 38.1ms\n",
      "Speed: 2.9ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT154.png: 480x640 (no detections), 39.8ms\n",
      "Speed: 2.9ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT155.png: 480x640 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT156.png: 480x640 (no detections), 38.3ms\n",
      "Speed: 2.9ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT157.png: 480x640 1 0, 37.2ms\n",
      "Speed: 3.0ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT158.png: 480x640 1 0, 41.9ms\n",
      "Speed: 3.0ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT159.png: 480x640 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT160.png: 480x640 (no detections), 38.6ms\n",
      "Speed: 3.0ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT161.png: 480x640 (no detections), 37.9ms\n",
      "Speed: 3.0ms preprocess, 37.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT162.png: 480x640 (no detections), 38.5ms\n",
      "Speed: 3.0ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT163.png: 480x640 (no detections), 39.3ms\n",
      "Speed: 3.0ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT164.png: 480x640 1 0, 37.3ms\n",
      "Speed: 3.0ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT165.png: 480x640 (no detections), 41.0ms\n",
      "Speed: 3.1ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT166.png: 480x640 (no detections), 43.0ms\n",
      "Speed: 3.8ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT167.png: 480x640 1 0, 37.2ms\n",
      "Speed: 3.0ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT168.png: 480x640 1 0, 40.7ms\n",
      "Speed: 3.3ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT169.png: 480x640 1 0, 40.7ms\n",
      "Speed: 3.0ms preprocess, 40.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT170.png: 480x640 1 0, 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT171.png: 480x640 (no detections), 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT172.png: 480x640 (no detections), 38.3ms\n",
      "Speed: 3.0ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT173.png: 480x640 (no detections), 39.2ms\n",
      "Speed: 3.0ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT174.png: 480x640 (no detections), 38.5ms\n",
      "Speed: 3.0ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT175.png: 480x640 (no detections), 37.8ms\n",
      "Speed: 3.0ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT176.png: 480x640 (no detections), 42.8ms\n",
      "Speed: 3.0ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT177.png: 480x640 1 0, 38.9ms\n",
      "Speed: 3.0ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT178.png: 480x640 1 0, 41.6ms\n",
      "Speed: 2.9ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT179.png: 480x640 1 0, 40.8ms\n",
      "Speed: 3.0ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT180.png: 480x640 (no detections), 39.5ms\n",
      "Speed: 3.0ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT181.png: 480x640 (no detections), 41.7ms\n",
      "Speed: 3.0ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT182.png: 480x640 1 0, 40.1ms\n",
      "Speed: 3.1ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT183.png: 480x640 (no detections), 41.9ms\n",
      "Speed: 3.0ms preprocess, 41.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT184.png: 480x640 (no detections), 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT185.png: 480x640 (no detections), 39.3ms\n",
      "Speed: 2.9ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT186.png: 480x640 (no detections), 39.7ms\n",
      "Speed: 3.0ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT187.png: 480x640 1 0, 41.6ms\n",
      "Speed: 2.9ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT188.png: 480x640 1 0, 39.5ms\n",
      "Speed: 3.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT189.png: 480x640 (no detections), 40.9ms\n",
      "Speed: 2.9ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 120, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 60, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 30, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 15, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 120, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT190.png: 480x640 (no detections), 39.1ms\n",
      "Speed: 2.9ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT191.png: 448x640 1 0, 41.2ms\n",
      "Speed: 2.9ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT192.png: 448x640 1 0, 42.0ms\n",
      "Speed: 2.8ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT193.png: 448x640 (no detections), 39.5ms\n",
      "Speed: 2.8ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT194.png: 448x640 (no detections), 39.0ms\n",
      "Speed: 2.8ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT195.png: 448x640 (no detections), 38.4ms\n",
      "Speed: 2.8ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT196.png: 448x640 (no detections), 38.0ms\n",
      "Speed: 2.8ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT197.png: 448x640 (no detections), 39.4ms\n",
      "Speed: 2.8ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT198.png: 448x640 (no detections), 39.2ms\n",
      "Speed: 3.1ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT199.png: 448x640 1 0, 39.0ms\n",
      "Speed: 2.8ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT200.png: 448x640 (no detections), 38.4ms\n",
      "Speed: 2.8ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 112, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 56, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 28, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 14, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 112, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT201.png: 448x640 (no detections), 40.1ms\n",
      "Speed: 2.7ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT202.png: 416x640 (no detections), 40.5ms\n",
      "Speed: 2.7ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT203.png: 416x640 1 0, 38.6ms\n",
      "Speed: 2.7ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT204.png: 416x640 1 0, 46.4ms\n",
      "Speed: 2.8ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT205.png: 416x640 1 0, 40.5ms\n",
      "Speed: 2.7ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT206.png: 416x640 (no detections), 41.2ms\n",
      "Speed: 2.7ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT207.png: 416x640 (no detections), 39.4ms\n",
      "Speed: 2.9ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT208.png: 416x640 (no detections), 40.6ms\n",
      "Speed: 2.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT209.png: 416x640 1 0, 40.1ms\n",
      "Speed: 2.8ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT210.png: 416x640 (no detections), 40.4ms\n",
      "Speed: 2.8ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT211.png: 416x640 (no detections), 40.8ms\n",
      "Speed: 2.7ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT212.png: 416x640 1 0, 45.1ms\n",
      "Speed: 2.7ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT213.png: 416x640 1 0, 40.2ms\n",
      "Speed: 2.6ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT214.png: 416x640 1 0, 42.8ms\n",
      "Speed: 2.7ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT215.png: 416x640 1 0, 42.4ms\n",
      "Speed: 2.6ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT216.png: 416x640 (no detections), 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT217.png: 416x640 1 0, 39.7ms\n",
      "Speed: 2.6ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT218.png: 416x640 (no detections), 39.0ms\n",
      "Speed: 2.7ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT219.png: 416x640 (no detections), 40.8ms\n",
      "Speed: 2.7ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT220.png: 416x640 (no detections), 38.1ms\n",
      "Speed: 2.7ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT221.png: 416x640 (no detections), 41.1ms\n",
      "Speed: 2.7ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT222.png: 416x640 (no detections), 38.1ms\n",
      "Speed: 2.7ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT223.png: 416x640 (no detections), 38.7ms\n",
      "Speed: 2.7ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT224.png: 416x640 (no detections), 38.8ms\n",
      "Speed: 2.7ms preprocess, 38.8ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT225.png: 416x640 (no detections), 40.6ms\n",
      "Speed: 2.7ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT226.png: 416x640 (no detections), 38.1ms\n",
      "Speed: 2.7ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT227.png: 416x640 (no detections), 39.6ms\n",
      "Speed: 2.7ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT228.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 2.7ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT229.png: 416x640 (no detections), 40.4ms\n",
      "Speed: 2.7ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT230.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 2.7ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT231.png: 416x640 (no detections), 39.1ms\n",
      "Speed: 2.7ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT232.png: 416x640 (no detections), 39.6ms\n",
      "Speed: 2.7ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT233.png: 416x640 (no detections), 40.4ms\n",
      "Speed: 2.6ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT234.png: 416x640 (no detections), 38.7ms\n",
      "Speed: 2.7ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT235.png: 416x640 (no detections), 39.0ms\n",
      "Speed: 2.6ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT236.png: 416x640 (no detections), 37.6ms\n",
      "Speed: 2.6ms preprocess, 37.6ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT237.png: 416x640 (no detections), 40.4ms\n",
      "Speed: 2.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT238.png: 416x640 (no detections), 38.2ms\n",
      "Speed: 2.6ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT239.png: 416x640 (no detections), 38.3ms\n",
      "Speed: 2.6ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT240.png: 416x640 (no detections), 38.9ms\n",
      "Speed: 2.6ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT242.png: 416x640 (no detections), 40.1ms\n",
      "Speed: 2.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 104, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 52, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 26, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 13, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 104, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT243.png: 416x640 (no detections), 37.3ms\n",
      "Speed: 2.6ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT244.png: 384x640 (no detections), 40.3ms\n",
      "Speed: 2.6ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT245.png: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.5ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT246.png: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.5ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT247.png: 384x640 (no detections), 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT248.png: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.6ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT249.png: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.6ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT250.png: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.5ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT251.png: 384x640 (no detections), 38.8ms\n",
      "Speed: 2.6ms preprocess, 38.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT252.png: 384x640 (no detections), 38.7ms\n",
      "Speed: 2.5ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT253.png: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.5ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT254.png: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT255.png: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.6ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT256.png: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.5ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT257.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.7ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT258.png: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.6ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT259.png: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.6ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT260.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.6ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT261.png: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.6ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT262.png: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.6ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT263.png: 384x640 (no detections), 37.6ms\n",
      "Speed: 2.6ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT264.png: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.7ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT265.png: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT266.png: 384x640 2 0s, 39.8ms\n",
      "Speed: 2.7ms preprocess, 39.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT267.png: 384x640 (no detections), 42.3ms\n",
      "Speed: 2.6ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT268.png: 384x640 (no detections), 40.5ms\n",
      "Speed: 2.6ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT269.png: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.6ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT270.png: 384x640 (no detections), 38.7ms\n",
      "Speed: 2.6ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT271.png: 384x640 (no detections), 38.7ms\n",
      "Speed: 2.6ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT272.png: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT273.png: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT274.png: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.6ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT275.png: 384x640 (no detections), 39.0ms\n",
      "Speed: 2.6ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT276.png: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.6ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT277.png: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.6ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT278.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.6ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT279.png: 384x640 (no detections), 39.4ms\n",
      "Speed: 2.7ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT280.png: 384x640 1 0, 39.0ms\n",
      "Speed: 2.7ms preprocess, 39.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT281.png: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT283.png: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT284.png: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.6ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT285.png: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.5ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT286.png: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.5ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT287.png: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.6ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT288.png: 384x640 (no detections), 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT289.png: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.6ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT290.png: 384x640 (no detections), 40.7ms\n",
      "Speed: 2.6ms preprocess, 40.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT291.png: 384x640 (no detections), 37.8ms\n",
      "Speed: 2.6ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT292.png: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.6ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT293.png: 384x640 (no detections), 39.0ms\n",
      "Speed: 2.6ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT294.png: 384x640 (no detections), 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT295.png: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.6ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT296.png: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.6ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT297.png: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT298.png: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.7ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 96, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 48, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 24, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 12, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 96, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT299.png: 384x640 (no detections), 44.6ms\n",
      "Speed: 2.7ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT300.png: 352x640 (no detections), 41.1ms\n",
      "Speed: 2.4ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT301.png: 352x640 (no detections), 39.0ms\n",
      "Speed: 2.4ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT302.png: 352x640 (no detections), 39.0ms\n",
      "Speed: 2.4ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT303.png: 352x640 (no detections), 39.0ms\n",
      "Speed: 2.4ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT304.png: 352x640 (no detections), 39.5ms\n",
      "Speed: 2.4ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 88, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 44, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 22, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 11, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 88, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT305.png: 352x640 (no detections), 39.7ms\n",
      "Speed: 2.4ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT306.png: 320x640 (no detections), 40.6ms\n",
      "Speed: 2.3ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT307.png: 320x640 (no detections), 38.4ms\n",
      "Speed: 2.2ms preprocess, 38.4ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT308.png: 320x640 (no detections), 40.0ms\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT309.png: 320x640 (no detections), 43.1ms\n",
      "Speed: 2.3ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT310.png: 320x640 (no detections), 40.9ms\n",
      "Speed: 2.2ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT311.png: 320x640 (no detections), 39.4ms\n",
      "Speed: 2.4ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT312.png: 320x640 (no detections), 40.8ms\n",
      "Speed: 2.2ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 80, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 40, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 20, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 10, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 80, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT313.png: 320x640 (no detections), 39.5ms\n",
      "Speed: 2.2ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT314.png: 288x640 (no detections), 41.2ms\n",
      "Speed: 2.3ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT315.png: 288x640 (no detections), 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT316.png: 288x640 (no detections), 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT317.png: 288x640 (no detections), 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT318.png: 288x640 (no detections), 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT319.png: 288x640 (no detections), 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 72, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 36, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 18, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 9, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 72, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT320.png: 288x640 (no detections), 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT321.png: 256x640 (no detections), 41.2ms\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT322.png: 256x640 (no detections), 39.2ms\n",
      "Speed: 1.9ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT323.png: 256x640 (no detections), 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT324.png: 256x640 (no detections), 40.0ms\n",
      "Speed: 1.9ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT325.png: 256x640 (no detections), 41.1ms\n",
      "Speed: 1.9ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT326.png: 256x640 (no detections), 40.5ms\n",
      "Speed: 1.9ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT327.png: 256x640 (no detections), 39.5ms\n",
      "Speed: 1.9ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT328.png: 256x640 (no detections), 41.7ms\n",
      "Speed: 1.9ms preprocess, 41.7ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT329.png: 256x640 (no detections), 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT330.png: 256x640 (no detections), 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT331.png: 256x640 (no detections), 40.5ms\n",
      "Speed: 1.9ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT332.png: 256x640 (no detections), 40.0ms\n",
      "Speed: 1.9ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT333.png: 256x640 (no detections), 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT334.png: 256x640 (no detections), 39.9ms\n",
      "Speed: 1.9ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT335.png: 256x640 (no detections), 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT336.png: 256x640 (no detections), 40.5ms\n",
      "Speed: 1.9ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT337.png: 256x640 (no detections), 40.9ms\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT338.png: 256x640 (no detections), 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 160])\n",
      "image 1/1 /export/home/daifang/ncr/Yolo11/ultralytics-main/testCT/1000868451_20230403_WBStandard_H_1001_CT339.png: 256x640 (no detections), 44.6ms\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# 定义预测函数\n",
    "def batch_predict_and_save(model, input_dir, output_label_dir):\n",
    "    # 创建输出目录\n",
    "    output_label_dir = Path(output_label_dir)\n",
    "    output_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 遍历输入目录中的所有 PNG 图像文件\n",
    "    for img_path in Path(input_dir).glob(\"*.png\"):\n",
    "        # 使用模型进行预测\n",
    "        results = model(img_path)\n",
    "\n",
    "        # 提取图像名（不带扩展名）用于保存\n",
    "        img_name = img_path.stem\n",
    "\n",
    "        # 读取图像尺寸\n",
    "        img = cv2.imread(str(img_path))\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # 保存预测框信息到文件\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()  # 提取边界框 (xyxy 格式)\n",
    "            for box in boxes:\n",
    "                # 计算归一化中心点坐标和宽高\n",
    "                x_center = (box[0] + box[2]) / 2 / w\n",
    "                y_center = (box[1] + box[3]) / 2 / h\n",
    "                width = (box[2] - box[0]) / w\n",
    "                height = (box[3] - box[1]) / h\n",
    "\n",
    "                # 将预测结果保存到 txt 文件\n",
    "                txt_file_path = output_label_dir / f\"{img_name}.txt\"\n",
    "                with open(txt_file_path, \"a\") as f:\n",
    "                    f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "model = YOLO('/export/home/daifang/ncr/Yolo11/ultralytics-main/ultralytics/cfg/models/11/yolo11_PPA_P2P5.yaml').load(\n",
    "    '/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/BONE_BOX_250117BESTTT/weights/best.pt')\n",
    "\n",
    "# # 定义输出文件路径\n",
    "# output_file = \"model.txt\"\n",
    "\n",
    "# # 打开文件进行写入\n",
    "# with open(output_file, 'w') as f:\n",
    "#     # 重定向输出到文件\n",
    "#     print(model, file=f)\n",
    "\n",
    "\n",
    "# 批量预测并\n",
    "batch_predict_and_save(\n",
    "    model=model,\n",
    "    input_dir=\"/export/home/daifang/ncr/Yolo11/ultralytics-main/testCT\",\n",
    "    output_label_dir=\"/export/home/daifang/ncr/Yolo11/ultralytics-main/testCT_result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0026.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0030.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0031.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0033.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0039.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0041.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0042.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0043.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0045.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0046.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0047.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0048.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0049.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0052.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0054.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0040.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0053.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0057.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0055.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0058.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0059.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0067.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0068.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0069.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0070.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0071.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0072.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0074.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0073.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0078.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0077.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0083.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0084.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0085.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0087.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0086.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0090.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0091.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0093.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0092.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0096.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0095.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0097.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0098.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0099.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0101.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0100.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0105.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0103.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0107.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0106.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0108.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0109.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0114.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0115.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0116.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0120.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0123.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0121.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0122.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0124.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0129.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0130.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0131.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0132.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0133.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0137.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0138.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0139.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0140.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0141.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0147.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0145.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0146.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0149.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0148.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0150.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0155.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0156.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0159.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0157.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0158.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0160.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0161.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0165.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0166.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0167.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0168.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0169.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0171.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0170.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0172.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0176.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0177.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0179.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0180.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0178.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0182.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0181.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0187.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0188.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0189.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0192.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0191.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0190.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0198.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0201.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0202.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0204.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0200.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0208.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0209.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0210.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0199.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0231.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0230.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0229.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0232.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0233.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0234.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0236.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0239.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0240.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0241.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0235.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0243.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0245.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0244.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0246.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0250.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0251.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0252.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0253.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0255.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0256.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0258.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0257.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0259.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0261.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0262.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0260.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0263.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0265.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0264.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0266.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0267.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0268.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0269.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0278.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0277.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0279.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0280.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0281.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0282.png\n",
      "✅ 保存可视化结果: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0283.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# 路径设置\n",
    "img_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/CT/\"         # 原图文件夹路径\n",
    "txt_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/result/\"         # 检测结果txt路径\n",
    "save_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/output/\"    # 可视化输出路径\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 遍历所有txt\n",
    "for txt_name in os.listdir(txt_dir):\n",
    "    if not txt_name.endswith(\".txt\"):\n",
    "        continue\n",
    "    \n",
    "    img_name = txt_name.replace(\".txt\", \".png\")\n",
    "    img_path = os.path.join(img_dir, img_name)\n",
    "    txt_path = os.path.join(txt_dir, txt_name)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ 无法找到 {img_path}\")\n",
    "        continue\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    # 读取检测框\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        cls, x_c, y_c, bw, bh = map(float, line.strip().split())\n",
    "        x1 = int((x_c - bw/2) * w)\n",
    "        y1 = int((y_c - bh/2) * h)\n",
    "        x2 = int((x_c + bw/2) * w)\n",
    "        y2 = int((y_c + bh/2) * h)\n",
    "\n",
    "        box_w = x2 - x1\n",
    "        box_h = y2 - y1\n",
    "\n",
    "        # 绘制矩形与尺寸\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        cv2.putText(img, f\"{int(box_w)}x{int(box_h)}\", (x1, y1-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
    "    \n",
    "    save_path = os.path.join(save_dir, img_name)\n",
    "    cv2.imwrite(save_path, img)\n",
    "    print(f\"✅ 保存可视化结果: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No txt file for 1000001854_0002.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0001.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0003.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0006.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0005.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0004.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0009.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0007.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0008.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0012.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0010.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0011.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0015.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0014.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0013.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0017.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0016.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0018.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0021.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0020.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0019.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0023.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0024.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0022.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0027.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0026.png\n",
      "⚠️ No txt file for 1000001854_0025.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0029.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0028.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0030.png\n",
      "⚠️ No txt file for 1000001854_0032.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0031.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0033.png\n",
      "⚠️ No txt file for 1000001854_0036.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0034.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0035.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0038.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0039.png\n",
      "⚠️ No txt file for 1000001854_0037.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0041.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0042.png\n",
      "⚠️ No txt file for 1000001854_0044.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0043.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0045.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0046.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0047.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0048.png\n",
      "⚠️ No txt file for 1000001854_0050.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0049.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0052.png\n",
      "⚠️ No txt file for 1000001854_0051.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0054.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0040.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0053.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0057.png\n",
      "⚠️ No txt file for 1000001854_0056.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0055.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0058.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0059.png\n",
      "⚠️ No txt file for 1000001854_0060.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0061.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0062.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0063.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0064.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0065.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0066.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0067.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0068.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0069.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0070.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0071.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0072.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0074.png\n",
      "⚠️ No txt file for 1000001854_0075.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0073.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0078.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0077.png\n",
      "⚠️ No txt file for 1000001854_0076.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0079.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0081.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0080.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0082.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0083.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0084.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0085.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0087.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0086.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0090.png\n",
      "⚠️ No txt file for 1000001854_0089.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0088.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0091.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0093.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0092.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0096.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0095.png\n",
      "⚠️ No txt file for 1000001854_0094.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0097.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0098.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0099.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0101.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0100.png\n",
      "⚠️ No txt file for 1000001854_0102.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0105.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0103.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0107.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0106.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0108.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0109.png\n",
      "⚠️ No txt file for 1000001854_0110.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0104.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0111.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0112.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0113.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0114.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0115.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0116.png\n",
      "⚠️ No txt file for 1000001854_0117.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0118.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0119.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0120.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0123.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0121.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0122.png\n",
      "⚠️ No txt file for 1000001854_0126.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0125.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0124.png\n",
      "⚠️ No txt file for 1000001854_0127.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0128.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0129.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0130.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0131.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0132.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0133.png\n",
      "⚠️ No txt file for 1000001854_0134.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0135.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0137.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0138.png\n",
      "⚠️ No txt file for 1000001854_0136.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0139.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0140.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0141.png\n",
      "⚠️ No txt file for 1000001854_0144.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0143.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0142.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0147.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0145.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0146.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0149.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0148.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0150.png\n",
      "⚠️ No txt file for 1000001854_0153.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0154.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0155.png\n",
      "⚠️ No txt file for 1000001854_0151.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0152.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0156.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0159.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0157.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0158.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0160.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0161.png\n",
      "⚠️ No txt file for 1000001854_0162.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0165.png\n",
      "⚠️ No txt file for 1000001854_0164.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0163.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0166.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0167.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0168.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0169.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0171.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0170.png\n",
      "⚠️ No txt file for 1000001854_0173.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0172.png\n",
      "⚠️ No txt file for 1000001854_0174.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0176.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0177.png\n",
      "⚠️ No txt file for 1000001854_0175.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0179.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0180.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0178.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0182.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0181.png\n",
      "⚠️ No txt file for 1000001854_0183.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0185.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0186.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0184.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0187.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0188.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0189.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0192.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0191.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0190.png\n",
      "⚠️ No txt file for 1000001854_0195.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0194.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0193.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0198.png\n",
      "⚠️ No txt file for 1000001854_0197.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0196.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0201.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0202.png\n",
      "⚠️ No txt file for 1000001854_0203.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0204.png\n",
      "⚠️ No txt file for 1000001854_0205.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0206.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0200.png\n",
      "⚠️ No txt file for 1000001854_0207.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0208.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0209.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0210.png\n",
      "⚠️ No txt file for 1000001854_0211.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0212.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0213.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0214.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0199.png\n",
      "⚠️ No txt file for 1000001854_0215.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0216.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0217.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0218.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0219.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0220.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0221.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0222.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0223.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0224.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0225.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0226.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0228.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0227.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0231.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0230.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0229.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0232.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0233.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0234.png\n",
      "⚠️ No txt file for 1000001854_0237.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0236.png\n",
      "⚠️ No txt file for 1000001854_0238.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0239.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0240.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0241.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0235.png\n",
      "⚠️ No txt file for 1000001854_0242.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0243.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0245.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0244.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0246.png\n",
      "⚠️ No txt file for 1000001854_0249.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0250.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0251.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0252.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0253.png\n",
      "⚠️ No txt file for 1000001854_0254.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0248.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0255.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0256.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0258.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0257.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0259.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0261.png\n",
      "⚠️ No txt file for 1000001854_0247.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0262.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0260.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0263.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0265.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0264.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0266.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0267.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0268.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0269.png\n",
      "⚠️ No txt file for 1000001854_0271.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0270.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0272.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0275.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0273.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0274.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0278.png\n",
      "⚠️ No txt file for 1000001854_0276.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0277.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0279.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0280.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0281.png\n",
      "⚠️ No txt file for 1000001854_0284.png, skipped.\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0282.png\n",
      "✅ Processed: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0283.png\n",
      "⚠️ No txt file for 1000001854_0286.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0285.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0287.png, skipped.\n",
      "🎯 All images processed! Results saved in 'output/'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# 输入文件夹\n",
    "img_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/CT\"\n",
    "txt_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/result\"\n",
    "output_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/output\"\n",
    "\n",
    "# 输出文件夹不存在则创建\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 遍历所有图像\n",
    "for img_file in os.listdir(img_dir):\n",
    "    if not (img_file.endswith(\".png\") or img_file.endswith(\".jpg\")):\n",
    "        continue\n",
    "\n",
    "    # 获取文件名（不带后缀）\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    img_path = os.path.join(img_dir, img_file)\n",
    "    txt_path = os.path.join(txt_dir, base_name + \".txt\")\n",
    "\n",
    "    # 如果没有对应的txt则跳过\n",
    "    if not os.path.exists(txt_path):\n",
    "        print(f\"⚠️ No txt file for {img_file}, skipped.\")\n",
    "        continue\n",
    "\n",
    "    # 读取图像\n",
    "    img = cv2.imread(img_path)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # 读取 YOLO txt 文件\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "\n",
    "        class_id, x_center, y_center, w, h = map(float, parts)\n",
    "\n",
    "        # 转换为像素坐标\n",
    "        x_center_pixel = int(x_center * W)\n",
    "        y_center_pixel = int(y_center * H)\n",
    "        w_pixel = int(w * W)\n",
    "        h_pixel = int(h * H)\n",
    "\n",
    "        x1 = int(x_center_pixel - w_pixel / 2)\n",
    "        y1 = int(y_center_pixel - h_pixel / 2)\n",
    "        x2 = int(x_center_pixel + w_pixel / 2)\n",
    "        y2 = int(y_center_pixel + h_pixel / 2)\n",
    "\n",
    "        # 绘制矩形框\n",
    "        color = (0, 0, 255)  # 红色\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # # 绘制类别标签\n",
    "        # cv2.putText(img, f\"Class {int(class_id)}\", (x1, max(y1 - 10, 0)),\n",
    "        #             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # 保存结果\n",
    "    out_path = os.path.join(output_dir, img_file)\n",
    "    cv2.imwrite(out_path, img)\n",
    "    print(f\"✅ Processed: {out_path}\")\n",
    "\n",
    "print(\"🎯 All images processed! Results saved in 'output/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No txt file for 1000001854_0002.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0001.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0003.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0006.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0005.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0004.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0009.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0007.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0008.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0012.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0010.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0011.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0015.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0014.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0013.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0017.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0016.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0018.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0021.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0020.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0019.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0023.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0024.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0022.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0027.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0026_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0026.png\n",
      "⚠️ No txt file for 1000001854_0025.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0029.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0028.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0030_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0030_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0030.png\n",
      "⚠️ No txt file for 1000001854_0032.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0031_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0031.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0033_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0033.png\n",
      "⚠️ No txt file for 1000001854_0036.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0034.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0035.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0038.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0039_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0039.png\n",
      "⚠️ No txt file for 1000001854_0037.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0041_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0041.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0042_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0042.png\n",
      "⚠️ No txt file for 1000001854_0044.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0043_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0043.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0045_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0045.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0046_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0046.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0047_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0047.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0048_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0048.png\n",
      "⚠️ No txt file for 1000001854_0050.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0049_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0049.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0052_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0052.png\n",
      "⚠️ No txt file for 1000001854_0051.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0054_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0054.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0040_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0040.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0053_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0053.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0057_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0057.png\n",
      "⚠️ No txt file for 1000001854_0056.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0055_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0055.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0058_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0058.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0059_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0059.png\n",
      "⚠️ No txt file for 1000001854_0060.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0061.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0062.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0063.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0064.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0065.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0066.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0067_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0067.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0068_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0068.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0069_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0069.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0070_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0070.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0071_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0071.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0072_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0072.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0074_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0074.png\n",
      "⚠️ No txt file for 1000001854_0075.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0073_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0073.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0078_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0078.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0077_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0077.png\n",
      "⚠️ No txt file for 1000001854_0076.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0079.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0081.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0080.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0082.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0083_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0083.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0084_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0084.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0085_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0085.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0087_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0087.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0086_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0086.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0090_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0090.png\n",
      "⚠️ No txt file for 1000001854_0089.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0088.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0091_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0091.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0093_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0093.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0092_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0092_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0092.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0096_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0096.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0095_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0095.png\n",
      "⚠️ No txt file for 1000001854_0094.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0097_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0097_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0097.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0098_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0098.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0099_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0099.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0101_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0101.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0100_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0100.png\n",
      "⚠️ No txt file for 1000001854_0102.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0105_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0105.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0103_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0103.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0107_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0107.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0106_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0106.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0108_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0108.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0109_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0109.png\n",
      "⚠️ No txt file for 1000001854_0110.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0104.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0111.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0112.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0113.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0114_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0114.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0115_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0115.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0116_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0116.png\n",
      "⚠️ No txt file for 1000001854_0117.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0118.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0119.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0120_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0120.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0123_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0123.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0121_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0121.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0122_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0122.png\n",
      "⚠️ No txt file for 1000001854_0126.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0125.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0124_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0124.png\n",
      "⚠️ No txt file for 1000001854_0127.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0128.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0129_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0129.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0130_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0130.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0131_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0131.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0132_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0132_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0132.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0133_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0133.png\n",
      "⚠️ No txt file for 1000001854_0134.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0135.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0137_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0137.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0138_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0138.png\n",
      "⚠️ No txt file for 1000001854_0136.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0139_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0139.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0140_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0140.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0141_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0141_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0141.png\n",
      "⚠️ No txt file for 1000001854_0144.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0143.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0142.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0147_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0147.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0145_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0145.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0146_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0146.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0149_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0149.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0148_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0148.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0150_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0150.png\n",
      "⚠️ No txt file for 1000001854_0153.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0154.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0155_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0155.png\n",
      "⚠️ No txt file for 1000001854_0151.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0152.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0156_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0156.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0159_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0159.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0157_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0157.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0158_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0158.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0160_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0160.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0161_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0161.png\n",
      "⚠️ No txt file for 1000001854_0162.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0165_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0165.png\n",
      "⚠️ No txt file for 1000001854_0164.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0163.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0166_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0166.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0167_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0167.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0168_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0168.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0169_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0169.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0171_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0171_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0171.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0170_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0170.png\n",
      "⚠️ No txt file for 1000001854_0173.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0172_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0172.png\n",
      "⚠️ No txt file for 1000001854_0174.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0176_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0176.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0177_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0177.png\n",
      "⚠️ No txt file for 1000001854_0175.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0179_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0179.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0180_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0180.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0178_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0178.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0182_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0182.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0181_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0181.png\n",
      "⚠️ No txt file for 1000001854_0183.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0185.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0186.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0184.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0187_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0187.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0188_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0188.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0189_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0189.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0192_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0192_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0192.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0191_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0191.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0190_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0190.png\n",
      "⚠️ No txt file for 1000001854_0195.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0194.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0193.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0198_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0198.png\n",
      "⚠️ No txt file for 1000001854_0197.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0196.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0201_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0201.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0202_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0202.png\n",
      "⚠️ No txt file for 1000001854_0203.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0204_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0204.png\n",
      "⚠️ No txt file for 1000001854_0205.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0206.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0200_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0200.png\n",
      "⚠️ No txt file for 1000001854_0207.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0208_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0208.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0209_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0209.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0210_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0210.png\n",
      "⚠️ No txt file for 1000001854_0211.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0212.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0213.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0214.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0199_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0199.png\n",
      "⚠️ No txt file for 1000001854_0215.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0216.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0217.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0218.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0219.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0220.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0221.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0222.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0223.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0224.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0225.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0226.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0228.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0227.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0231_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0231_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0231.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0230_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0230_crop2.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0230_crop3.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0230.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0229_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0229_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0229.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0232_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0232_crop2.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0232_crop3.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0232.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0233_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0233_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0233.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0234_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0234_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0234.png\n",
      "⚠️ No txt file for 1000001854_0237.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0236_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0236.png\n",
      "⚠️ No txt file for 1000001854_0238.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0239_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0239.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0240_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0240_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0240.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0241_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0241.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0235_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0235_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0235.png\n",
      "⚠️ No txt file for 1000001854_0242.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0243_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0243.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0245_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0245.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0244_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0244.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0246_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0246.png\n",
      "⚠️ No txt file for 1000001854_0249.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0250_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0250_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0250.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0251_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0251.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0252_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0252.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0253_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0253.png\n",
      "⚠️ No txt file for 1000001854_0254.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0248.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0255_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0255.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0256_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0256.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0258_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0258_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0258.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0257_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0257_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0257.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0259_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0259_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0259.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0261_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0261_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0261.png\n",
      "⚠️ No txt file for 1000001854_0247.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0262_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0262.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0260_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0260_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0260.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0263_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0263_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0263.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0265_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0265.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0264_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0264.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0266_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0266.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0267_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0267.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0268_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0268.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0269_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0269.png\n",
      "⚠️ No txt file for 1000001854_0271.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0270.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0272.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0275.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0273.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0274.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0278_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0278_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0278.png\n",
      "⚠️ No txt file for 1000001854_0276.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0277_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0277.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0279_crop1.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0279_crop2.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0279.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0280_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0280.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0281_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0281.png\n",
      "⚠️ No txt file for 1000001854_0284.png, skipped.\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0282_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0282.png\n",
      "✂️ Saved crop: /export/home/daifang/ncr/Yolo11/ultralytics-main/CT/crops/1000001854_0283_crop1.png\n",
      "✅ Saved original: /export/home/daifang/ncr/Yolo11/ultralytics-main/output/1000001854_0283.png\n",
      "⚠️ No txt file for 1000001854_0286.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0285.png, skipped.\n",
      "⚠️ No txt file for 1000001854_0287.png, skipped.\n",
      "🎯 All images processed! Crops saved in 'CT/crops/', originals in 'output/'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# 输入文件夹\n",
    "img_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/CT\"\n",
    "txt_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/result\"\n",
    "output_dir = \"/export/home/daifang/ncr/Yolo11/ultralytics-main/output\"\n",
    "crop_dir = os.path.join(img_dir, \"crops\")  # 在CT下新建crops文件夹\n",
    "\n",
    "# 输出文件夹不存在则创建\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "# 遍历所有图像\n",
    "for img_file in os.listdir(img_dir):\n",
    "    if not (img_file.endswith(\".png\") or img_file.endswith(\".jpg\")):\n",
    "        continue\n",
    "\n",
    "    # 获取文件名（不带后缀）\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    img_path = os.path.join(img_dir, img_file)\n",
    "    txt_path = os.path.join(txt_dir, base_name + \".txt\")\n",
    "\n",
    "    # 如果没有对应的txt则跳过\n",
    "    if not os.path.exists(txt_path):\n",
    "        print(f\"⚠️ No txt file for {img_file}, skipped.\")\n",
    "        continue\n",
    "\n",
    "    # 读取图像\n",
    "    img = cv2.imread(img_path)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # 读取 YOLO txt 文件\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    crop_index = 1  # 每张图的裁剪编号\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "\n",
    "        class_id, x_center, y_center, w, h = map(float, parts)\n",
    "\n",
    "        # 转换为像素坐标\n",
    "        x_center_pixel = int(x_center * W)\n",
    "        y_center_pixel = int(y_center * H)\n",
    "        w_pixel = int(w * W)\n",
    "        h_pixel = int(h * H)\n",
    "\n",
    "        x1 = max(0, int(x_center_pixel - w_pixel / 2))\n",
    "        y1 = max(0, int(y_center_pixel - h_pixel / 2))\n",
    "        x2 = min(W, int(x_center_pixel + w_pixel / 2))\n",
    "        y2 = min(H, int(y_center_pixel + h_pixel / 2))\n",
    "\n",
    "        # 裁剪检测框区域（不带红框）\n",
    "        crop_img = img[y1:y2, x1:x2]\n",
    "\n",
    "        # 保存裁剪结果\n",
    "        crop_path = os.path.join(crop_dir, f\"{base_name}_crop{crop_index}.png\")\n",
    "        cv2.imwrite(crop_path, crop_img)\n",
    "        print(f\"✂️ Saved crop: {crop_path}\")\n",
    "\n",
    "        crop_index += 1\n",
    "\n",
    "    # 保存一份原始图到 output 目录（不画框）\n",
    "    out_path = os.path.join(output_dir, img_file)\n",
    "    cv2.imwrite(out_path, img)\n",
    "    print(f\"✅ Saved original: {out_path}\")\n",
    "\n",
    "print(\"🎯 All images processed! Crops saved in 'CT/crops/', originals in 'output/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 8, 8])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 8, 8])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 64, 64])\n",
      "Transferred 869/869 items from pretrained weights\n",
      "model class info:{0: '0'}\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 8, 8])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 4, 4])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 2, 2])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 1, 1])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 2, 2])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 160])\n",
      "YOLO11_PPA_P2P5 summary: 573 layers, 2,933,928 parameters, 2,933,912 gradients, 12.1 GFLOPs\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/435 [00:00<00:00, 13057.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 160, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 80, 80])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 40, 40])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 20, 20])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 160, 160])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 35.6ms\n",
      "Speed: 0.0ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 14937.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/435 [00:00<00:00, 10488.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/435 [00:00<00:00, 1805.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 25/435 [00:00<00:00, 14871.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 14073.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning... self.method(tensor, [self.target]) failure.\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/435 [00:00<00:00, 7549.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/435 [00:00<00:00, 15936.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/435 [00:00<00:00, 3785.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/435 [00:00<00:00, 12595.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 4951.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 99.0ms\n",
      "Speed: 0.1ms preprocess, 99.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 12106.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 36.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 20/435 [00:00<00:00, 10307.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 35.9ms\n",
      "Speed: 0.0ms preprocess, 35.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/435 [00:00<00:00, 9803.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 35.9ms\n",
      "Speed: 0.0ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 24/435 [00:00<00:00, 10730.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 11567.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 38/435 [00:00<00:00, 16210.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/435 [00:00<00:00, 16198.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 32.3ms\n",
      "Speed: 0.0ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 17806.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 36/435 [00:00<00:00, 16015.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 17188.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 32.3ms\n",
      "Speed: 0.0ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 17045.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 16464.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 17003.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 17042.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 17295.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 16850.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/435 [00:00<00:00, 17047.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/435 [00:00<00:00, 17042.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 15600.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 49/435 [00:00<00:00, 6368.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 11206.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 12238.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 11170.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 37.3ms\n",
      "Speed: 0.0ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 66/435 [00:00<00:00, 12349.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 69/435 [00:00<00:00, 9197.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 32.4ms\n",
      "Speed: 0.0ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 73/435 [00:00<00:00, 17633.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16323.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 68/435 [00:00<00:00, 17549.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 81/435 [00:00<00:00, 5250.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 76/435 [00:00<00:00, 18011.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 74/435 [00:00<00:00, 17588.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 31.8ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 84/435 [00:00<00:00, 18103.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 72/435 [00:00<00:00, 18015.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 66/435 [00:00<00:00, 17661.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 57/435 [00:00<00:00, 17411.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 42/435 [00:00<00:00, 14412.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 17037.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 46/435 [00:00<00:00, 16986.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/435 [00:00<00:00, 17609.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17649.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 57/435 [00:00<00:00, 17179.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 17064.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 32.1ms\n",
      "Speed: 0.0ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 73/435 [00:00<00:00, 18268.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17769.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/435 [00:00<00:00, 16011.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16496.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 62/435 [00:00<00:00, 17667.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 20 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 54/435 [00:00<00:00, 17495.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16984.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/435 [00:00<00:00, 16135.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15477.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17760.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/435 [00:00<00:00, 16525.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/435 [00:00<00:00, 16585.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/435 [00:00<00:00, 17244.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/435 [00:00<00:00, 17579.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17489.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/435 [00:00<00:00, 15625.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 17288.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17216.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 16918.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 62/435 [00:00<00:00, 17815.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 76/435 [00:00<00:00, 17880.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 16793.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/435 [00:00<00:00, 15653.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 58/435 [00:00<00:00, 17055.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/435 [00:00<00:00, 16632.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 16766.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15214.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/435 [00:00<00:00, 17333.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/435 [00:00<00:00, 15757.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 26/435 [00:00<00:00, 14961.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/435 [00:00<00:00, 15333.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 38/435 [00:00<00:00, 16057.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 46/435 [00:00<00:00, 17122.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 14168.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.9ms\n",
      "Speed: 0.0ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16348.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 21/435 [00:00<00:00, 14036.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/435 [00:00<00:00, 15813.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 20/435 [00:00<00:00, 13865.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15283.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/435 [00:00<00:00, 16823.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 15769.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 49/435 [00:00<00:00, 17106.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 16135.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 17234.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17484.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/435 [00:00<00:00, 15686.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/435 [00:00<00:00, 15497.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 16783.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16272.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/435 [00:00<00:00, 15563.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/435 [00:00<00:00, 11040.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 42/435 [00:00<00:00, 16261.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 36/435 [00:00<00:00, 15862.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/435 [00:00<00:00, 17243.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 16120.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 25/435 [00:00<00:00, 15061.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 61/435 [00:00<00:00, 17704.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16406.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 24/435 [00:00<00:00, 15347.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17493.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15196.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/435 [00:00<00:00, 13025.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 15987.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 45/435 [00:00<00:00, 16962.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 64/435 [00:00<00:00, 17865.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 22 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17951.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 20 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 57/435 [00:00<00:00, 17619.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 20 0s, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/435 [00:00<00:00, 16404.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/435 [00:00<00:00, 16994.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/435 [00:00<00:00, 16403.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/435 [00:00<00:00, 16708.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 16779.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 16875.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 68/435 [00:00<00:00, 17795.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 64/435 [00:00<00:00, 15547.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 20 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17391.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/435 [00:00<00:00, 12968.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15118.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/435 [00:00<00:00, 13711.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 16763.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/435 [00:00<00:00, 13886.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/435 [00:00<00:00, 17058.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17789.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17373.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/435 [00:00<00:00, 11941.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/435 [00:00<00:00, 17676.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 57/435 [00:00<00:00, 17551.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/435 [00:00<00:00, 11763.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 2 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/435 [00:00<00:00, 16181.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 37.1ms\n",
      "Speed: 0.0ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 16/435 [00:00<00:00, 13148.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 15610.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17514.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/435 [00:00<00:00, 17885.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 68/435 [00:00<00:00, 17957.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 21 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15749.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 73/435 [00:00<00:00, 18144.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 28 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 41/435 [00:00<00:00, 16806.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10790.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10852.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 11459.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/435 [00:00<00:00, 14358.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 2 0s, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 17135.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15900.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 58/435 [00:00<00:00, 14336.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 62/435 [00:00<00:00, 17871.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17826.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 11560.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/435 [00:00<00:00, 12498.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 83/435 [00:00<00:00, 18329.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 27 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 11503.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 22/435 [00:00<00:00, 14605.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10727.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 69/435 [00:00<00:00, 18118.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 17147.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/435 [00:00<00:00, 17930.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 77/435 [00:00<00:00, 18498.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 29 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 49/435 [00:00<00:00, 16513.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 86/435 [00:00<00:00, 18634.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 29 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 11351.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.9ms\n",
      "Speed: 0.0ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10793.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10771.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 56/435 [00:00<00:00, 17405.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15883.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/435 [00:00<00:00, 10749.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 1 0, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 85/435 [00:00<00:00, 18686.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 28 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 81/435 [00:00<00:00, 18367.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 19 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/435 [00:00<00:00, 18189.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 64/435 [00:00<00:00, 18244.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 68/435 [00:00<00:00, 17825.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 69/435 [00:00<00:00, 17894.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 24 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/435 [00:00<00:00, 17394.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17759.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17965.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 31.9ms\n",
      "Speed: 0.0ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/435 [00:00<00:00, 17774.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 86/435 [00:00<00:00, 18623.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 30 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 54/435 [00:00<00:00, 17431.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15275.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/435 [00:00<00:00, 17498.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/435 [00:00<00:00, 9902.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.4ms\n",
      "Speed: 0.0ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 76/435 [00:00<00:00, 18145.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 84/435 [00:00<00:00, 18612.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 84/435 [00:00<00:00, 18539.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 18 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/435 [00:00<00:00, 17845.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 58/435 [00:00<00:00, 17581.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/435 [00:00<00:00, 17485.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 24/435 [00:00<00:00, 15319.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/435 [00:00<00:00, 15730.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15738.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/435 [00:00<00:00, 15979.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 15981.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15789.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 37/435 [00:00<00:00, 16744.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 26/435 [00:00<00:00, 14961.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 14422.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 44/435 [00:00<00:00, 16859.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 46/435 [00:00<00:00, 16964.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 42/435 [00:00<00:00, 16454.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15940.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 59/435 [00:00<00:00, 17702.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16535.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 93/435 [00:00<00:00, 18549.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 20 0s, 31.2ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 66/435 [00:00<00:00, 17815.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 78/435 [00:00<00:00, 18262.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/435 [00:00<00:00, 18022.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 93/435 [00:00<00:00, 18126.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 89/435 [00:00<00:00, 18446.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 89/435 [00:00<00:00, 18607.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 77/435 [00:00<00:00, 18196.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 32.3ms\n",
      "Speed: 0.0ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 88/435 [00:00<00:00, 18338.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 42.5ms\n",
      "Speed: 0.0ms preprocess, 42.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 80/435 [00:00<00:00, 18164.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.5ms\n",
      "Speed: 0.0ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 85/435 [00:00<00:00, 18614.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 80/435 [00:00<00:00, 17970.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 89/435 [00:00<00:00, 18818.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 15 0s, 31.1ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 72/435 [00:00<00:00, 18063.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/435 [00:00<00:00, 17773.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/435 [00:00<00:00, 17902.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/435 [00:00<00:00, 17618.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 62/435 [00:00<00:00, 18090.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/435 [00:00<00:00, 12277.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 12 0s, 36.1ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/435 [00:00<00:00, 11006.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 36.6ms\n",
      "Speed: 0.0ms preprocess, 36.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 98/435 [00:00<00:00, 12845.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 119/435 [00:00<00:00, 12979.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 24 0s, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 74/435 [00:00<00:00, 12579.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 21 0s, 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 71/435 [00:00<00:00, 12406.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 16 0s, 36.3ms\n",
      "Speed: 0.0ms preprocess, 36.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/435 [00:00<00:00, 6788.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 85/435 [00:00<00:00, 12760.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 14 0s, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 86/435 [00:00<00:00, 12672.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 17 0s, 36.3ms\n",
      "Speed: 0.0ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 74/435 [00:00<00:00, 12622.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/435 [00:00<00:00, 12468.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 36.1ms\n",
      "Speed: 0.0ms preprocess, 36.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 73/435 [00:00<00:00, 12355.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 13 0s, 79.8ms\n",
      "Speed: 0.0ms preprocess, 79.8ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15930.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.9ms\n",
      "Speed: 0.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/435 [00:00<00:00, 16705.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 15494.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 68/435 [00:00<00:00, 17909.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 11 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 25/435 [00:00<00:00, 15078.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 15949.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/435 [00:00<00:00, 16630.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 8 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 15516.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15773.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/435 [00:00<00:00, 15588.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 3 0s, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/435 [00:00<00:00, 15518.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/435 [00:00<00:00, 16832.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 9 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/435 [00:00<00:00, 17666.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 10 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/435 [00:00<00:00, 16176.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/435 [00:00<00:00, 15238.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 30.6ms\n",
      "Speed: 0.0ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/435 [00:00<00:00, 15709.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 7 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/435 [00:00<00:00, 16221.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 6 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/435 [00:00<00:00, 16076.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/435 [00:00<00:00, 13951.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/435 [00:00<00:00, 12808.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 2 0s, 30.8ms\n",
      "Speed: 0.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/435 [00:00<00:00, 16121.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 5 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 21/435 [00:00<00:00, 14259.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.6ms\n",
      "Speed: 0.0ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/435 [00:00<00:00, 12842.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/435 [00:00<00:00, 14236.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 31.1ms\n",
      "Speed: 0.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/435 [00:00<00:00, 12834.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 16/435 [00:00<00:00, 13171.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 16/435 [00:00<00:00, 13161.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 2 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 20/435 [00:00<00:00, 14191.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 4 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:torch.Size([1, 3, 512, 512])\n",
      "self.method:<pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus object at 0x7f3becc17d60>\n",
      "self.target:yolo_detect_target()\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/435 [00:00<00:00, 12114.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 32, 128, 128])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 64, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 256, 64, 64])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 192, 32, 32])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 384, 16, 16])\n",
      "Forwarding C3k2_PPA with input shape: torch.Size([1, 128, 128, 128])\n",
      "0: 512x512 2 0s, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import torch, yaml, cv2, os, shutil, sys, copy\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.tasks import attempt_load_weights\n",
    "from ultralytics.utils.torch_utils import intersect_dicts\n",
    "from ultralytics.utils.ops import xywh2xyxy, non_max_suppression\n",
    "from pytorch_grad_cam import GradCAMPlusPlus, GradCAM, XGradCAM, EigenCAM, HiResCAM, LayerCAM, RandomCAM, EigenGradCAM, KPCA_CAM, AblationCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "from pytorch_grad_cam.activations_and_gradients import ActivationsAndGradients\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, ratio, (top, bottom, left, right)\n",
    "\n",
    "class ActivationsAndGradients:\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers, reshape_transform):\n",
    "        self.model = model\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        self.reshape_transform = reshape_transform\n",
    "        self.handles = []\n",
    "        for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))\n",
    "            # Because of https://github.com/pytorch/pytorch/issues/61519,\n",
    "            # we don't use backward hook to record gradients.\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        activation = output\n",
    "\n",
    "        if self.reshape_transform is not None:\n",
    "            activation = self.reshape_transform(activation)\n",
    "        self.activations.append(activation.cpu().detach())\n",
    "\n",
    "    def save_gradient(self, module, input, output):\n",
    "        if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "            # You can only register hooks on tensor requires grad.\n",
    "            return\n",
    "\n",
    "        # Gradients are computed in reverse order\n",
    "        def _store_grad(grad):\n",
    "            if self.reshape_transform is not None:\n",
    "                grad = self.reshape_transform(grad)\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "\n",
    "        output.register_hook(_store_grad)\n",
    "\n",
    "    def post_process(self, result):\n",
    "        if self.model.end2end:\n",
    "            logits_ = result[:, :, 4:]\n",
    "            boxes_ = result[:, :, :4]\n",
    "            sorted, indices = torch.sort(logits_[:, :, 0], descending=True)\n",
    "            return logits_[0][indices[0]], boxes_[0][indices[0]]\n",
    "        elif self.model.task == 'detect':\n",
    "            logits_ = result[:, 4:]\n",
    "            boxes_ = result[:, :4]\n",
    "            sorted, indices = torch.sort(logits_.max(1)[0], descending=True)\n",
    "            return torch.transpose(logits_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(boxes_[0], dim0=0, dim1=1)[indices[0]]\n",
    "        elif self.model.task == 'segment':\n",
    "            logits_ = result[0][:, 4:4 + self.model.nc]\n",
    "            boxes_ = result[0][:, :4]\n",
    "            mask_p, mask_nm = result[1][2].squeeze(), result[1][1].squeeze().transpose(1, 0)\n",
    "            c, h, w = mask_p.size()\n",
    "            mask = (mask_nm @ mask_p.view(c, -1))\n",
    "            sorted, indices = torch.sort(logits_.max(1)[0], descending=True)\n",
    "            return torch.transpose(logits_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(boxes_[0], dim0=0, dim1=1)[indices[0]], mask[indices[0]]\n",
    "        elif self.model.task == 'pose':\n",
    "            logits_ = result[:, 4:4 + self.model.nc]\n",
    "            boxes_ = result[:, :4]\n",
    "            poses_ = result[:, 4 + self.model.nc:]\n",
    "            sorted, indices = torch.sort(logits_.max(1)[0], descending=True)\n",
    "            return torch.transpose(logits_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(boxes_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(poses_[0], dim0=0, dim1=1)[indices[0]]\n",
    "        elif self.model.task == 'obb':\n",
    "            logits_ = result[:, 4:4 + self.model.nc]\n",
    "            boxes_ = result[:, :4]\n",
    "            angles_ = result[:, 4 + self.model.nc:]\n",
    "            sorted, indices = torch.sort(logits_.max(1)[0], descending=True)\n",
    "            return torch.transpose(logits_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(boxes_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(angles_[0], dim0=0, dim1=1)[indices[0]]\n",
    "        elif self.model.task == 'classify':\n",
    "            return result[0]\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        model_output = self.model(x)\n",
    "        if self.model.task == 'detect':\n",
    "            post_result, pre_post_boxes = self.post_process(model_output[0])\n",
    "            return [[post_result, pre_post_boxes]]\n",
    "        elif self.model.task == 'segment':\n",
    "            post_result, pre_post_boxes, pre_post_mask = self.post_process(model_output)\n",
    "            return [[post_result, pre_post_boxes, pre_post_mask]]\n",
    "        elif self.model.task == 'pose':\n",
    "            post_result, pre_post_boxes, pre_post_pose = self.post_process(model_output[0])\n",
    "            return [[post_result, pre_post_boxes, pre_post_pose]]\n",
    "        elif self.model.task == 'obb':\n",
    "            post_result, pre_post_boxes, pre_post_angle = self.post_process(model_output[0])\n",
    "            return [[post_result, pre_post_boxes, pre_post_angle]]\n",
    "        elif self.model.task == 'classify':\n",
    "            data = self.post_process(model_output)\n",
    "            return [data]\n",
    "\n",
    "    def release(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "\n",
    "class yolo_detect_target(torch.nn.Module):\n",
    "    def __init__(self, ouput_type, conf, ratio, end2end) -> None:\n",
    "        super().__init__()\n",
    "        self.ouput_type = ouput_type\n",
    "        self.conf = conf\n",
    "        self.ratio = ratio\n",
    "        self.end2end = end2end\n",
    "    \n",
    "    def forward(self, data):\n",
    "        post_result, pre_post_boxes = data\n",
    "        result = []\n",
    "        for i in trange(int(post_result.size(0) * self.ratio)):\n",
    "            if (self.end2end and float(post_result[i, 0]) < self.conf) or (not self.end2end and float(post_result[i].max()) < self.conf):\n",
    "                break\n",
    "            if self.ouput_type == 'class' or self.ouput_type == 'all':\n",
    "                if self.end2end:\n",
    "                    result.append(post_result[i, 0])\n",
    "                else:\n",
    "                    result.append(post_result[i].max())\n",
    "            elif self.ouput_type == 'box' or self.ouput_type == 'all':\n",
    "                for j in range(4):\n",
    "                    result.append(pre_post_boxes[i, j])\n",
    "        return sum(result)\n",
    "\n",
    "class yolo_segment_target(yolo_detect_target):\n",
    "    def __init__(self, ouput_type, conf, ratio, end2end):\n",
    "        super().__init__(ouput_type, conf, ratio, end2end)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        post_result, pre_post_boxes, pre_post_mask = data\n",
    "        result = []\n",
    "        for i in trange(int(post_result.size(0) * self.ratio)):\n",
    "            if float(post_result[i].max()) < self.conf:\n",
    "                break\n",
    "            if self.ouput_type == 'class' or self.ouput_type == 'all':\n",
    "                result.append(post_result[i].max())\n",
    "            elif self.ouput_type == 'box' or self.ouput_type == 'all':\n",
    "                for j in range(4):\n",
    "                    result.append(pre_post_boxes[i, j])\n",
    "            elif self.ouput_type == 'segment' or self.ouput_type == 'all':\n",
    "                result.append(pre_post_mask[i].mean())\n",
    "        return sum(result)\n",
    "\n",
    "\n",
    "class yolo_pose_target(yolo_detect_target):\n",
    "    def __init__(self, ouput_type, conf, ratio, end2end):\n",
    "        super().__init__(ouput_type, conf, ratio, end2end)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        post_result, pre_post_boxes, pre_post_pose = data\n",
    "        result = []\n",
    "        for i in trange(int(post_result.size(0) * self.ratio)):\n",
    "            if float(post_result[i].max()) < self.conf:\n",
    "                break\n",
    "            if self.ouput_type == 'class' or self.ouput_type == 'all':\n",
    "                result.append(post_result[i].max())\n",
    "            elif self.ouput_type == 'box' or self.ouput_type == 'all':\n",
    "                for j in range(4):\n",
    "                    result.append(pre_post_boxes[i, j])\n",
    "            elif self.ouput_type == 'pose' or self.ouput_type == 'all':\n",
    "                result.append(pre_post_pose[i].mean())\n",
    "        return sum(result)\n",
    "\n",
    "class yolo_obb_target(yolo_detect_target):\n",
    "    def __init__(self, ouput_type, conf, ratio, end2end):\n",
    "        super().__init__(ouput_type, conf, ratio, end2end)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        post_result, pre_post_boxes, pre_post_angle = data\n",
    "        result = []\n",
    "        for i in trange(int(post_result.size(0) * self.ratio)):\n",
    "            if float(post_result[i].max()) < self.conf:\n",
    "                break\n",
    "            if self.ouput_type == 'class' or self.ouput_type == 'all':\n",
    "                result.append(post_result[i].max())\n",
    "            elif self.ouput_type == 'box' or self.ouput_type == 'all':\n",
    "                for j in range(4):\n",
    "                    result.append(pre_post_boxes[i, j])\n",
    "            elif self.ouput_type == 'obb' or self.ouput_type == 'all':\n",
    "                result.append(pre_post_angle[i])\n",
    "        return sum(result)\n",
    "\n",
    "class yolo_classify_target(yolo_detect_target):\n",
    "    def __init__(self, ouput_type, conf, ratio, end2end):\n",
    "        super().__init__(ouput_type, conf, ratio, end2end)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return data.max()\n",
    "\n",
    "class yolo_heatmap:\n",
    "    def __init__(self, cfg, weight, device, method, layer, backward_type, conf_threshold, ratio, show_result, renormalize, task, img_size):\n",
    "        device = torch.device(device)\n",
    "        model_yolo = YOLO(cfg)  \n",
    "        model_yolo.load(weight)  \n",
    "        model_names = model_yolo.names\n",
    "        print(f'model class info:{model_names}')\n",
    "        model = copy.deepcopy(model_yolo.model)\n",
    "        model.to(device)\n",
    "        model.info()\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        model.eval()\n",
    "        \n",
    "        model.task = task\n",
    "        if not hasattr(model, 'end2end'):\n",
    "            model.end2end = False\n",
    "        \n",
    "        if task == 'detect':\n",
    "            target = yolo_detect_target(backward_type, conf_threshold, ratio, model.end2end)\n",
    "        elif task == 'segment':\n",
    "            target = yolo_segment_target(backward_type, conf_threshold, ratio, model.end2end)\n",
    "        elif task == 'pose':\n",
    "            target = yolo_pose_target(backward_type, conf_threshold, ratio, model.end2end)\n",
    "        elif task == 'obb':\n",
    "            target = yolo_obb_target(backward_type, conf_threshold, ratio, model.end2end)\n",
    "        elif task == 'classify':\n",
    "            target = yolo_classify_target(backward_type, conf_threshold, ratio, model.end2end)\n",
    "        else:\n",
    "            raise Exception(f\"not support task({task}).\")\n",
    "        \n",
    "        target_layers = [model.model[l] for l in layer]\n",
    "        method = eval(method)(model, target_layers)\n",
    "        method.activations_and_grads = ActivationsAndGradients(model, target_layers, None)\n",
    "        \n",
    "        colors = np.random.uniform(0, 255, size=(len(model_names), 3)).astype(np.int32)\n",
    "        self.__dict__.update(locals())\n",
    "    \n",
    "    def post_process(self, result):\n",
    "        result = non_max_suppression(result, conf_thres=self.conf_threshold, iou_thres=0.65)[0]\n",
    "        return result\n",
    "\n",
    "    def draw_detections(self, box, color, name, img):\n",
    "        xmin, ymin, xmax, ymax = list(map(int, list(box)))\n",
    "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), tuple(int(x) for x in color), 2) # 绘制检测框\n",
    "        cv2.putText(img, str(name), (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, tuple(int(x) for x in color), 2, lineType=cv2.LINE_AA)  # 绘制类别、置信度\n",
    "        return img\n",
    "\n",
    "    def renormalize_cam_in_bounding_boxes(self, boxes, image_float_np, grayscale_cam):\n",
    "        \"\"\"Normalize the CAM to be in the range [0, 1] \n",
    "        inside every bounding boxes, and zero outside of the bounding boxes. \"\"\"\n",
    "        renormalized_cam = np.zeros(grayscale_cam.shape, dtype=np.float32)\n",
    "        for x1, y1, x2, y2 in boxes:\n",
    "            x1, y1 = max(x1, 0), max(y1, 0)\n",
    "            x2, y2 = min(grayscale_cam.shape[1] - 1, x2), min(grayscale_cam.shape[0] - 1, y2)\n",
    "            renormalized_cam[y1:y2, x1:x2] = scale_cam_image(grayscale_cam[y1:y2, x1:x2].copy())    \n",
    "        renormalized_cam = scale_cam_image(renormalized_cam)\n",
    "        eigencam_image_renormalized = show_cam_on_image(image_float_np, renormalized_cam, use_rgb=True)\n",
    "        return eigencam_image_renormalized\n",
    "    \n",
    "    def process(self, img_path, save_path):\n",
    "        # img process\n",
    "        try:\n",
    "            img = cv2.imdecode(np.fromfile(img_path, np.uint8), cv2.IMREAD_COLOR)\n",
    "        except:\n",
    "            print(f\"Warning... {img_path} read failure.\")\n",
    "            return\n",
    "        img, _, (top, bottom, left, right) = letterbox(img, new_shape=(self.img_size, self.img_size), auto=False) # 如果需要完全固定成宽高一样就把auto设置为False\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.float32(img) / 255.0\n",
    "        tensor = torch.from_numpy(np.transpose(img, axes=[2, 0, 1])).unsqueeze(0).to(self.device)\n",
    "        print(f'tensor size:{tensor.size()}')\n",
    "        \n",
    "        try:\n",
    "            # 计算CAM\n",
    "            print(f'self.method:{self.method}')\n",
    "            print(f'self.target:{self.target}')\n",
    "            grayscale_cam = self.method(tensor, [self.target])\n",
    "        except AttributeError as e:\n",
    "            print(f\"Warning... self.method(tensor, [self.target]) failure.\")\n",
    "            return\n",
    "        \n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        # 在热力图上应用双边滤波\n",
    "        grayscale_cam = cv2.bilateralFilter(grayscale_cam, d=9, sigmaColor=100, sigmaSpace=100)\n",
    "\n",
    "        \n",
    "        cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "        \n",
    "        pred = self.model_yolo.predict(tensor, conf=self.conf_threshold, iou=0.7)[0]\n",
    "        if self.renormalize and self.task in ['detect', 'segment', 'pose']:\n",
    "            cam_image = self.renormalize_cam_in_bounding_boxes(pred.boxes.xyxy.cpu().detach().numpy().astype(np.int32), img, grayscale_cam)\n",
    "        if self.show_result:\n",
    "            cam_image = pred.plot(img=cam_image,\n",
    "                                  conf=False, # 显示置信度\n",
    "                                  font_size=None, # 字体大小，None为根据当前image尺寸计算\n",
    "                                  line_width=None, # 线条宽度，None为根据当前image尺寸计算\n",
    "                                  labels=False, # 显示标签\n",
    "                                  )\n",
    "        \n",
    "        # 去掉padding边界\n",
    "        cam_image = cam_image[top:cam_image.shape[0] - bottom, left:cam_image.shape[1] - right]\n",
    "        cam_image = Image.fromarray(cam_image)\n",
    "        cam_image.save(save_path)\n",
    "    \n",
    "    def __call__(self, img_path, save_path):\n",
    "        # remove dir if exist\n",
    "        if os.path.exists(save_path):\n",
    "            shutil.rmtree(save_path)\n",
    "        # make dir if not exist\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(img_path):\n",
    "            for img_path_ in os.listdir(img_path):\n",
    "                self.process(f'{img_path}/{img_path_}', f'{save_path}/{img_path_}')\n",
    "        else:\n",
    "            self.process(img_path, f'{save_path}/result.png')\n",
    "        \n",
    "def get_params():\n",
    "    params = {\n",
    "        'cfg': '/export/home/daifang/ncr/Yolo11/ultralytics-main/ultralytics/cfg/models/11/yolo11_PPA_P2P5.yaml',\n",
    "        # 'weight': '/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/BONE_BOX_250307/weights/last.pt', \n",
    "        'weight': '/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/BONE_BOX_250117BESTTT/weights/best.pt',\n",
    "        'device': 'cuda:0',\n",
    "        'method': 'GradCAMPlusPlus', # GradCAMPlusPlus, GradCAM, XGradCAM, EigenCAM, HiResCAM, LayerCAM, RandomCAM, EigenGradCAM, KPCA_CAM\n",
    "        'layer': [13,15,17,18, 20, 21, 22, 23, 24,26],\n",
    "        'backward_type': 'all', # detect:<class, box, all> segment:<class, box, segment, all> pose:<box, keypoint, all> obb:<box, angle, all> classify:<all>\n",
    "        'conf_threshold': 0.01, # 0.2\n",
    "        'ratio': 0.02, # 0.02-0.1\n",
    "        'show_result': False, # 不需要绘制结果请设置为False\n",
    "        'renormalize': False, # 需要把热力图限制在框内请设置为True(仅对detect,segment,pose有效)\n",
    "        'task':'detect', # 任务(detect,segment,pose,obb,classify)\n",
    "        'img_size':512, # 图像尺寸\n",
    "    }\n",
    "    return params\n",
    "\n",
    "# pip install grad-cam==1.5.4 --no-deps\n",
    "if __name__ == '__main__':\n",
    "    model = yolo_heatmap(**get_params())\n",
    "    # model(r'/home/hjj/Desktop/dataset/dataset_coco/coco/images/val2017/000000361238.jpg', 'result')\n",
    "    # model(r'H:\\bone_metastasis\\total_data\\4class\\4class\\Osteolytic_deal\\CT_Bone', 'Osteolytic_deal_result')\n",
    "    # model('/export/home/daifang/ncr/data/normal_chest', '/export/home/daifang/ncr/data/normal_grad_result1')\n",
    "    # model('/export/home/daifang/ncr/Yolo11/datasets_0422/images/train', '/export/home/daifang/ncr/CAM/result')\n",
    "    model('/export/home/daifang/ncr/Yolo11/ultralytics-main/CT', '/export/home/daifang/ncr/CAM/result')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'C3k2_PPA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m                         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_center\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_center\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/export/home/daifang/ncr/Yolo11/ultralytics-main/ultralytics/cfg/models/11/yolo11_CAFM_PPA_P2.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/0511_PPA_CAFM2/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 定义输入目录和输出文件夹路径\u001b[39;00m\n\u001b[1;32m     63\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/export/home/daifang/ncr/data/CT_ORIGINAL\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/engine/model.py:146\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28m__import__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUBLAS_WORKSPACE_CONFIG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:4096:8\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# to avoid deterministic warnings\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(model)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(model, task\u001b[38;5;241m=\u001b[39mtask)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/engine/model.py:256\u001b[0m, in \u001b[0;36mModel._new\u001b[0;34m(self, cfg, task, model, verbose)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m task \u001b[38;5;129;01mor\u001b[39;00m guess_model_task(cfg_dict)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mRANK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build model\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/nn/tasks.py:325\u001b[0m, in \u001b[0;36mDetectionModel.__init__\u001b[0;34m(self, cfg, ch, nc, verbose)\u001b[0m\n\u001b[1;32m    323\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding model.yaml nc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with nc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m nc  \u001b[38;5;66;03m# override YAML value\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;241m=\u001b[39m \u001b[43mparse_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# model, savelist\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m {i: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m])}  \u001b[38;5;66;03m# default names dict\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/nn/tasks.py:1162\u001b[0m, in \u001b[0;36mparse_model\u001b[0;34m(d, ch, verbose)\u001b[0m\n\u001b[1;32m   1137\u001b[0m repeat_modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(  \u001b[38;5;66;03m# modules with 'repeat' arguments\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     {\n\u001b[1;32m   1139\u001b[0m         BottleneckCSP,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     }\n\u001b[1;32m   1155\u001b[0m )\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (f, n, m, args) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m]):  \u001b[38;5;66;03m# from, number, module, args\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnn, m[\u001b[38;5;241m3\u001b[39m:])\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28m__import__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mops, m[\u001b[38;5;241m16\u001b[39m:])\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision.ops.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m\n\u001b[0;32m-> 1162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1163\u001b[0m     )  \u001b[38;5;66;03m# get module\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args):\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'C3k2_PPA'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# 定义预测函数\n",
    "def batch_predict_and_save(model, input_dir, output_base_dir, max_folders=None):\n",
    "    # 创建输出目录的根路径\n",
    "    output_base_dir = Path(output_base_dir)\n",
    "    output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 获取输入目录中的所有病人ID文件夹\n",
    "    patient_folders = [f for f in Path(input_dir).iterdir() if f.is_dir()]\n",
    "\n",
    "    # 如果指定了max_folders，限制处理的文件夹数量\n",
    "    if max_folders:\n",
    "        patient_folders = patient_folders[:max_folders]\n",
    "\n",
    "    # 遍历病人文件夹\n",
    "    for patient_folder in patient_folders:\n",
    "        # 创建该病人ID文件夹的输出目录\n",
    "        patient_output_dir = output_base_dir / patient_folder.name\n",
    "        patient_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 创建保存预测框信息的 box_txt 文件夹\n",
    "        box_txt_dir = patient_output_dir / \"box_txt\"\n",
    "        box_txt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 遍历病人文件夹中的所有 PNG 图像文件\n",
    "        for img_path in patient_folder.glob(\"*.png\"):\n",
    "            # 使用模型进行预测\n",
    "            results = model(img_path)\n",
    "\n",
    "            # 提取图像名（不带扩展名）用于保存\n",
    "            img_name = img_path.stem\n",
    "\n",
    "            # 读取图像尺寸\n",
    "            img = cv2.imread(str(img_path))\n",
    "            h, w = img.shape[:2]\n",
    "\n",
    "            # 保存预测框信息到文件\n",
    "            for result in results:\n",
    "                boxes = result.boxes.xyxy.cpu().numpy()  # 提取边界框 (xyxy 格式)\n",
    "                for box in boxes:\n",
    "                    # 计算归一化中心点坐标和宽高\n",
    "                    x_center = (box[0] + box[2]) / 2 / w\n",
    "                    y_center = (box[1] + box[3]) / 2 / h\n",
    "                    width = (box[2] - box[0]) / w\n",
    "                    height = (box[3] - box[1]) / h\n",
    "\n",
    "                    # 将预测结果保存到 txt 文件\n",
    "                    txt_file_path = box_txt_dir / f\"{img_name}.txt\"\n",
    "                    with open(txt_file_path, \"a\") as f:\n",
    "                        f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "model = YOLO(r'H:\\bone_metastasis\\Yolov11\\ultralytics-main\\ultralytics-main\\runs\\train\\0511_PPA_CAFM2\\yolo11_CAFM_PPA_P2.yaml').load(\n",
    "    r\"H:\\bone_metastasis\\Yolov11\\ultralytics-main\\ultralytics-main\\runs\\train\\0511_PPA_CAFM2\\weights\\best.pt\")\n",
    "\n",
    "# 定义输入目录和输出文件夹路径\n",
    "input_dir = r\"H:\\bone_metastasis\\total_data\\train_data\\CT_ORIGINAL_wuhead512\"\n",
    "output_base_dir = r\"H:\\bone_metastasis\\Yolov11\\ultralytics-main\\ultralytics-main\\result_predict\"\n",
    "\n",
    "# 设置要处理的病人文件夹的最大数量\n",
    "max_folders = 100  # 设置为处理5个文件夹，您可以根据需要修改这个数字\n",
    "\n",
    "# 批量预测并保存结果\n",
    "batch_predict_and_save(\n",
    "    model=model,\n",
    "    input_dir=input_dir,\n",
    "    output_base_dir=output_base_dir,\n",
    "    max_folders=max_folders\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0094.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0104.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0124.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0130.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0150.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0160.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0161.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0162.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0165.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0166.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0170.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0171.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0179.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0180.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0181.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0185.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0210.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0211.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0219.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0220.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0209.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0221.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0225.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0230.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0231.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0232.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0233.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0244.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000354500/RedPET\n",
      "复制 1000354500_0071.png 到 RedPET 文件夹.\n",
      "复制 1000354500 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0008.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0094.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0104.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0118.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0121.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0130.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0152.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0159.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0160.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0165.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0166.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0190.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0171.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0199.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0201.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0198.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0202.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0210.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0211.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0212.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0213.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0214.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0215.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0216.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0217.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0224.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0237.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000536501/RedPET\n",
      "复制 1000536501_0242.png 到 RedPET 文件夹.\n",
      "复制 1000536501 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0006.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0007.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0009.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0096.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0105.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0114.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0115.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0117.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0127.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0135.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0142.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0163.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0165.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0166.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0169.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0180.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0181.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0190.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0191.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0194.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0205.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000445742/RedPET\n",
      "复制 1000445742_0206.png 到 RedPET 文件夹.\n",
      "复制 1000445742 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0005.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0007.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0008.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0009.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0096.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0104.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0105.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0117.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0121.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0124.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0127.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0130.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0140.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0142.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0150.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0151.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0152.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0159.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0160.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0161.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0165.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0170.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0171.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0176.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0177.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0192.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0206.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000459589/RedPET\n",
      "复制 1000459589_0198.png 到 RedPET 文件夹.\n",
      "复制 1000459589 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0003.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0001.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0004.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0006.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0008.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0076.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0104.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0114.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0121.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0127.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0130.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0140.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0159.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0179.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0180.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0181.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0183.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0186.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0189.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0190.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0191.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000526086/RedPET\n",
      "复制 1000526086_0192.png 到 RedPET 文件夹.\n",
      "复制 1000526086 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0001.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0006.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0007.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0002.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0135.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0140.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0142.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0169.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0150.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0151.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0152.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0176.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0177.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0180.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0181.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0183.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0186.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0187.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0188.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0189.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0190.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0191.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0193.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0194.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0197.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0198.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0200.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0201.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0185.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000492401/RedPET\n",
      "复制 1000492401_0143.png 到 RedPET 文件夹.\n",
      "复制 1000492401 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0076.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0096.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0118.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0121.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0124.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0140.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0142.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0152.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0160.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0163.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0169.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0170.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0171.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0176.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0177.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0179.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0183.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0185.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0186.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0187.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0188.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0189.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0192.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0193.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0201.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0202.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0203.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0204.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0209.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0210.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0211.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0212.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0213.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0214.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0218.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0224.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0225.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0226.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0231.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0232.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0238.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000535152/RedPET\n",
      "复制 1000535152_0127.png 到 RedPET 文件夹.\n",
      "复制 1000535152 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0094.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0096.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0104.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0105.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0114.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0152.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0163.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0200.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0201.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0204.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0206.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0209.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0210.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0211.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0212.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0214.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0226.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000493861/RedPET\n",
      "复制 1000493861_0225.png 到 RedPET 文件夹.\n",
      "复制 1000493861 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0002.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0007.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0003.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0008.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0113.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0121.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0131.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0135.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0163.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0165.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0166.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0168.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0176.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0177.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0178.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0187.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0188.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0189.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0192.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0193.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0194.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0199.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0206.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516142/RedPET\n",
      "复制 1000516142_0201.png 到 RedPET 文件夹.\n",
      "复制 1000516142 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0002.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0005.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0006.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0009.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0076.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0114.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0115.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0122.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0124.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0132.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0135.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0142.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0164.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0171.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0191.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0192.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0194.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0197.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0198.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0203.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0204.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0205.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0206.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000516356/RedPET\n",
      "复制 1000516356_0207.png 到 RedPET 文件夹.\n",
      "复制 1000516356 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0004.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0010.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0007.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0033.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0065.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0066.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0076.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0089.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0094.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0115.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0096.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0117.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0118.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0123.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0127.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0130.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0149.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0150.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0151.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0153.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0155.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0159.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0170.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0189.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0190.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0199.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0200.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0201.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0203.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0204.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0205.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000518861/RedPET\n",
      "复制 1000518861_0206.png 到 RedPET 文件夹.\n",
      "复制 1000518861 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0002.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0003.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0008.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0009.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0011.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0012.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0013.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0015.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0016.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0017.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0014.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0018.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0019.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0020.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0021.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0022.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0023.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0024.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0025.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0026.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0027.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0028.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0029.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0030.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0031.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0032.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0034.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0035.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0036.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0037.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0040.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0043.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0047.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0053.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0054.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0071.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0076.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0077.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0092.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0102.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0105.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0112.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0114.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0115.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0117.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0124.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0133.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0134.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0140.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0141.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0143.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0159.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0183.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0184.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0185.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000520669/RedPET\n",
      "复制 1000520669_0206.png 到 RedPET 文件夹.\n",
      "复制 1000520669 的 CT 文件夹内容到 CT 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0038.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0039.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0041.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0042.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0045.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0046.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0048.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0049.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0044.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0050.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0051.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0052.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0055.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0056.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0058.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0059.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0060.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0057.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0061.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0063.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0064.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0062.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0067.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0068.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0069.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0070.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0072.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0073.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0075.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0078.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0079.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0080.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0074.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0081.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0082.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0083.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0084.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0085.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0087.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0088.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0086.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0090.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0091.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0093.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0095.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0097.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0094.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0098.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0099.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0100.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0101.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0103.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0106.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0107.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0108.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0109.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0110.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0111.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0116.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0117.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0118.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0119.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0120.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0125.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0126.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0127.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0128.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0129.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0136.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0137.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0138.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0139.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0135.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0144.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0145.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0146.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0147.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0148.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0150.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0154.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0156.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0157.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0158.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0162.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0166.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0167.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0169.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0172.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0173.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0174.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0175.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0177.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0182.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0185.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0193.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0194.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0195.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0196.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0210.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0219.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0212.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0221.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0223.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0224.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0225.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0227.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0228.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0229.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0230.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0231.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0235.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0241.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0242.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0243.png 到 RedPET 文件夹.\n",
      "/export/home/daifang/ncr/data/pred_yolo_100/result_predict/1000522095/RedPET\n",
      "复制 1000522095_0247.png 到 RedPET 文件夹.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m ct_original_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/export/home/daifang/ncr/data/CT_ORIGINAL\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 执行文件复制操作\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mcopy_files_based_on_box_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_predict_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mred_pet_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct_original_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 47\u001b[0m, in \u001b[0;36mcopy_files_based_on_box_img\u001b[0;34m(result_predict_dir, red_pet_dir, ct_original_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m             shutil\u001b[38;5;241m.\u001b[39mcopytree(item, ct_folder \u001b[38;5;241m/\u001b[39m item\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m             \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m复制 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 的 CT 文件夹内容到 CT 文件夹.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def copy_files_based_on_box_img(result_predict_dir, red_pet_dir, ct_original_dir):\n",
    "    # 获取 result_predict 中的所有病人ID文件夹\n",
    "    patient_folders = [f for f in Path(result_predict_dir).iterdir() if f.is_dir()]\n",
    "\n",
    "    # 遍历每个病人文件夹\n",
    "    for patient_folder in patient_folders:\n",
    "        # 获取病人ID，文件夹名就是病人ID\n",
    "        patient_id = patient_folder.name\n",
    "        \n",
    "        # 创建 CT 和 RedPET 文件夹\n",
    "        ct_folder = patient_folder / \"CT\"\n",
    "        redpet_folder = patient_folder / \"RedPET\"\n",
    "        \n",
    "        # 如果没有这些文件夹则创建\n",
    "        ct_folder.mkdir(parents=True, exist_ok=True)\n",
    "        redpet_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 遍历病人文件夹中的 box_img 文件夹中的所有 png 文件\n",
    "        box_img_dir = patient_folder / \"box_img\"\n",
    "        for img_path in box_img_dir.glob(\"*.png\"):\n",
    "            # 提取图像文件名（不带扩展名）\n",
    "            img_name = img_path.stem\n",
    "            \n",
    "            # 生成目标路径：从 red_pet_dir 复制同名文件到 RedPET 文件夹\n",
    "            corresponding_redpet_img_path = Path(red_pet_dir) / f\"{img_name}.png\"\n",
    "            print(redpet_folder)\n",
    "            if corresponding_redpet_img_path.exists():\n",
    "                # 复制文件到 RedPET 文件夹\n",
    "                shutil.copy(corresponding_redpet_img_path, redpet_folder / f\"{img_name}.png\")\n",
    "                print(f\"复制 {img_name}.png 到 RedPET 文件夹.\")\n",
    "            else:\n",
    "                print(f\"在 Red_PET_512all 中找不到图像: {img_name}.png, 跳过.\")\n",
    "\n",
    "        # 从 CT_ORIGINAL 中复制病人ID文件夹内容到 CT 文件夹\n",
    "        corresponding_ct_folder = Path(ct_original_dir) / patient_id\n",
    "        if corresponding_ct_folder.exists():\n",
    "            # 遍历病人ID文件夹中的所有文件和子文件夹\n",
    "            for item in corresponding_ct_folder.iterdir():\n",
    "                # 复制文件或子文件夹\n",
    "                if item.is_dir():\n",
    "                    shutil.copytree(item, ct_folder / item.name)\n",
    "                else:\n",
    "                    shutil.copy(item, ct_folder / item.name)\n",
    "            print(f\"复制 {patient_id} 的 CT 文件夹内容到 CT 文件夹.\")\n",
    "        else:\n",
    "            print(f\"在 CT_ORIGINAL 中找不到病人ID文件夹: {patient_id}, 跳过.\")\n",
    "\n",
    "# 定义路径\n",
    "result_predict_dir = \"/export/home/daifang/ncr/data/pred_yolo_100/result_predict\"\n",
    "red_pet_dir = \"/export/home/daifang/ncr/data/Red_PET_512all\"\n",
    "ct_original_dir = \"/export/home/daifang/ncr/data/CT_ORIGINAL\"\n",
    "\n",
    "# 执行文件复制操作\n",
    "copy_files_based_on_box_img(result_predict_dir, red_pet_dir, ct_original_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics.nn.modules.PPA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/0511_PPA_CAFM2/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 查看模型的所有层及其参数\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/serialization.py:1471\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1479\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/serialization.py:1953\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1952\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics.nn.modules.PPA'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 加载模型\n",
    "model = torch.load('/export/home/daifang/ncr/Yolo11/ultralytics-main/runs/train/0511_PPA_CAFM2/weights/best.pt', map_location='cpu')\n",
    "\n",
    "# 查看模型的所有层及其参数\n",
    "for name, param in model.items():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
